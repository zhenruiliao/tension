{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FORCE learning - bit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M43YMDGnSKoa"
      },
      "source": [
        "# FORCE Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKWB6NrYSD-W",
        "outputId": "a83b2dde-47b0-4b64-e394-26889824aa0c"
      },
      "source": [
        "!pip install --upgrade -q https://storage.googleapis.com/jax-wheels/cuda$(echo $CUDA_VERSION | sed -e 's/\\.//' -e 's/\\..*//')/jaxlib-0.1.8-cp36-none-linux_x86_64.whl\n",
        "!pip install --upgrade -q jax"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: jaxlib-0.1.8-cp36-none-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 708 kB 31.5 MB/s \n",
            "\u001b[?25h  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcxEC8gRzl6V"
      },
      "source": [
        "### Import some packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lQQBbkVSCif"
      },
      "source": [
        "from jax import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DORhgNUqEZD5",
        "outputId": "a26d6169-279e-4399-bc26-c1186c466095"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend, activations\n",
        " \n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcMw6rioJNfA"
      },
      "source": [
        "**Lorentz Attractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW--DmJFJXkn"
      },
      "source": [
        "T = 1.2            # total time\n",
        "u = 2               # number of inputs (didn't bother to set up zero, just put in zeros)\n",
        "n = 250            # size of the reservoir in the ESN\n",
        "tau = 0.02         # neuron time constant\n",
        "dt = tau / 10.0     # Euler integration step\n",
        "time = np.arange(0, T, dt) # all time\n",
        "ntime = time.shape[0]      # the number of time steps\n",
        "\n",
        "x_t = np.zeros((ntime,u)) # Just a stand-in in folks want a real input later\n",
        "indices = np.random.choice(x_t.shape[0] *x_t.shape[1], replace=False,\n",
        "                           size=int(x_t.shape[0] *x_t.shape[1]*0.025))\n",
        "x_t[np.unravel_index(indices, x_t.shape)] = 0.375\n",
        "\n",
        "for i in range(x_t.shape[0]):\n",
        "  if np.sum(x_t[i-10:i,:]) > 0:\n",
        "    x_t [i,:] = 0\n",
        "\n",
        "g = 1.5  # Lower g value was shown to be good in the paper for training.\n",
        "m = 1\n",
        "alpha = 1e0 # Initial learning rate for RLS\n",
        "dtdivtau = dt / tau\n",
        "\n",
        "input1 = tf.cast(tf.expand_dims(x_t,0),np.float32)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLcAV3Fvs-2t"
      },
      "source": [
        "from scipy.signal import butter,filtfilt, lfilter, sosfilt\n",
        "\n",
        "cutoff = 3\n",
        "fs = 30.0 \n",
        "nyq = 0.5 * fs\n",
        "order = 2\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order):\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    # Get the filter coefficients \n",
        "    sos = butter(order, normal_cutoff, btype='low', analog=False, output='sos')\n",
        "    y = sosfilt(sos, data)\n",
        "    # b, a = butter(order, normal_cutoff, btype='low', analog=False, output='ba')\n",
        "    # y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXNcXZNZWJg9"
      },
      "source": [
        "f_t_1 = np.zeros((x_t.shape[0],1))-1\n",
        "\n",
        "def func(f_t_1, x_t):\n",
        "  for i in range(1,x_t.shape[0]):\n",
        "    if np.sum(x_t[i,:]) == 0 or np.sum(x_t[i,:]) == 0.375*2:\n",
        "      f_t_1[i,0] = f_t_1[i-1,0] \n",
        "    elif x_t[i,0] == 0.375:\n",
        "      f_t_1[i,0] = min(f_t_1[i-1,0] + 2, 1)\n",
        "    elif x_t[i,1] == 0.375:\n",
        "      f_t_1[i,0] = max(f_t_1[i-1,0] - 2, -1)\n",
        "  return f_t_1\n",
        "f_t_1 =  func(f_t_1, x_t) \n",
        "f_t_1[:,0] = butter_lowpass_filter(f_t_1[:,0], cutoff, fs, order)\n",
        "f_t_1 = tf.cast(f_t_1,np.float32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7ATpEMu4UUwQ",
        "outputId": "08c265af-0c51-4b46-d6c3-9602288e5781"
      },
      "source": [
        "f, (ax0, ax1, ax2) = plt.subplots(nrows = 3, sharex = True,figsize = (18,6))\n",
        "\n",
        "ax0.plot(f_t_1[:,0])\n",
        "ax1.plot(x_t[:,0])\n",
        "ax2.plot(x_t[:,1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd832350490>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA9SiEthSCpv"
      },
      "source": [
        "# Generate randomness\n",
        "\n",
        "def keygen(key, nkeys):\n",
        "  \"\"\"Generate randomness that JAX can use by splitting the JAX keys.\n",
        "  Args:\n",
        "    key : the random.PRNGKey for JAX\n",
        "    nkeys : how many keys in key generator\n",
        "  Returns:\n",
        "    2-tuple (new key for further generators, key generator)\n",
        "  \"\"\"\n",
        "  keys = random.split(key, nkeys+1)\n",
        "  return keys[0], (k for k in keys[1:])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU5Nx6LLSCtA"
      },
      "source": [
        "def random_esn_params(key, u, n, m, tau=1.0, dt=0.1, g=1.0):\n",
        "  \"\"\"Generate random RNN parameters\n",
        "  \n",
        "  Arguments: \n",
        "    u: dim of the input\n",
        "    n: dim of the hidden state\n",
        "    m: dim of the output\n",
        "    tau: \"neuronal\" time constant\n",
        "    dt: time between Euler integration updates\n",
        "    g: scaling of the recurrent matrix in the reservoir\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of parameters for the ESN.\n",
        "  \"\"\"\n",
        "\n",
        "  key, skeys = keygen(key, 5)\n",
        "  hscale = 0.25\n",
        "  ifactor = 1.0 / np.sqrt(u)\n",
        "  hfactor = g / np.sqrt(n)\n",
        "  pfactor = 1.0 / np.sqrt(n)\n",
        "  ffactor = 1.0 # Feedback factor, keep at 1 for now.\n",
        "  return {'a0' : random.normal(next(skeys), (n,)) * hscale,\n",
        "          'wI' : random.normal(next(skeys), (n,u)) * ifactor,\n",
        "          'wR' : random.normal(next(skeys), (n,n)) * hfactor,\n",
        "          'wO' : random.normal(next(skeys), (m,n)) * pfactor,\n",
        "          'wF' : random.normal(next(skeys), (n,m)) * ffactor,\n",
        "          'dt_over_tau' : dt / tau}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raPy_St-SlR0"
      },
      "source": [
        "# params_seed = np.random.randint(0, 10000000)\n",
        "# print(\"Params seed %d\" %(params_seed))\n",
        "# key = random.PRNGKey(params_seed)\n",
        "# init_params = random_esn_params(key, u, n, m, g=g)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeRfrjLNIiip"
      },
      "source": [
        "# def lorenz(x, y, z, s=10, r=28, b=2.667):\n",
        "#     \"\"\"\n",
        "#     Given:\n",
        "#        x, y, z: a point of interest in three dimensional space\n",
        "#        s, r, b: parameters defining the lorenz attractor\n",
        "#     Returns:\n",
        "#        x_dot, y_dot, z_dot: values of the lorenz attractor's partial\n",
        "#            derivatives at the point x, y, z\n",
        "#     \"\"\"\n",
        "#     x_dot = s*(y - x)\n",
        "#     y_dot = r*x - y - x*z\n",
        "#     z_dot = x*y - b*z\n",
        "#     return x_dot, y_dot, z_dot\n",
        "\n",
        "\n",
        "# num_steps = ntime\n",
        "\n",
        "# # Need one more for the initial values\n",
        "# xs = np.empty(num_steps + 1)\n",
        "# ys = np.empty(num_steps + 1)\n",
        "# zs = np.empty(num_steps + 1)\n",
        "\n",
        "# # Set initial values\n",
        "# xs[0], ys[0], zs[0] = (0,-1,0.25)\n",
        "\n",
        "# # Step through \"time\", calculating the partial derivatives at the current point\n",
        "# # and using them to estimate the next point\n",
        "# for i in range(num_steps):\n",
        "#     x_dot, y_dot, z_dot = lorenz(xs[i], ys[i], zs[i])\n",
        "#     xs[i + 1] = xs[i] + (x_dot * dt)\n",
        "#     ys[i + 1] = ys[i] + (y_dot * dt)\n",
        "#     zs[i + 1] = zs[i] + (z_dot * dt)\n",
        "\n",
        "# f_t_1 = (tf.expand_dims(tf.convert_to_tensor(np.float32(xs[:ntime])), axis = 1)/10)[::3] #(xs**2+ys**2+zs**2)**0.5\n",
        "# #f_t_1 = (tf.expand_dims(tf.convert_to_tensor(np.float32(f_t_1[:ntime])),axis = 1)/100)[::10]\n",
        "# input1 = input1[0,::3]\n",
        "# time = time[::3]\n",
        "# plt.figure(figsize = (12,6))\n",
        "# plt.scatter(time, f_t_1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8jm6642TWjQ"
      },
      "source": [
        "# wI = tf.transpose(tf.convert_to_tensor(init_params['wI']))\n",
        "# wR = tf.transpose(tf.convert_to_tensor(init_params['wR']))\n",
        "# wF = tf.transpose(tf.convert_to_tensor(init_params['wF']))\n",
        "# wO = tf.transpose(tf.convert_to_tensor(init_params['wO']))\n",
        "# a0 = np.arctanh(np.linalg.pinv(wO.numpy()))*f_t_1[0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcNQNrHUALWq"
      },
      "source": [
        "class FORCELayer(keras.layers.AbstractRNNCell):\n",
        "    def __init__(self, units, output_size, activation, seed = None, g = 1.5, \n",
        "                 input_kernel_trainable = False, recurrent_kernel_trainable = False, \n",
        "                 output_kernel_trainable = True, feedback_kernel_trainable = False, **kwargs):\n",
        "      \n",
        "        self.units = units \n",
        "        self.__output_size__ = output_size\n",
        "        self.activation = activations.get(activation)\n",
        "\n",
        "        if seed is None:\n",
        "          self.__seed_gen__ = tf.random.Generator.from_non_deterministic_state()\n",
        "        else:\n",
        "          self.__seed_gen__ = tf.random.Generator.from_seed(seed)\n",
        "        \n",
        "        self.__g__ = g\n",
        "\n",
        "        self.__input_kernel_trainable__ = input_kernel_trainable\n",
        "        self.__recurrent_kernel_trainable__ = recurrent_kernel_trainable\n",
        "        self.__feedback_kernel_trainable__ = feedback_kernel_trainable\n",
        "        self.__output_kernel_trainable__ = output_kernel_trainable\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        return [self.units, self.units, self.output_size]\n",
        "\n",
        "    @property \n",
        "    def output_size(self):\n",
        "        return self.__output_size__\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.input_kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1/input_shape[-1]**0.5, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]),\n",
        "          trainable=self.__input_kernel_trainable__,\n",
        "          name='input_kernel')\n",
        " \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "          shape=(self.units, self.units),\n",
        "          initializer= keras.initializers.RandomNormal(mean=0., \n",
        "                                                       stddev= self.__g__/self.units**0.5, \n",
        "                                                       seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                  minval=None, \n",
        "                                                                                  dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__recurrent_kernel_trainable__,\n",
        "          name='recurrent_kernel')\n",
        "        \n",
        "        self.feedback_kernel = self.add_weight(\n",
        "          shape=(self.output_size, self.units), \n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__feedback_kernel_trainable__,\n",
        "          name='feedback_kernel')\n",
        "        \n",
        "        self.output_kernel = self.add_weight(\n",
        "          shape=(self.units, self.output_size),\n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1/self.units**0.5, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__output_kernel_trainable__,\n",
        "          name='output_kernel')      \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    @classmethod\n",
        "    def from_weights(cls, weights, **kwargs):\n",
        "        # Initialize the network from a list of weights (e.g., user-generated)\n",
        "        input_kernel, recurrent_kernel, feedback_kernel, output_kernel = weights \n",
        "        input_shape, input_units = input_kernel.shape \n",
        "        recurrent_units1, recurrent_units2 = recurrent_kernel.shape \n",
        "        feedback_output_size, feedback_units = feedback_kernel.shape \n",
        "        output_units, output_size = output_kernel.shape \n",
        "\n",
        "\n",
        "        units = input_units \n",
        "        assert np.all(np.array([input_units, recurrent_units1, recurrent_units2, \n",
        "                            feedback_units, output_units]) == units)\n",
        "\n",
        "        assert feedback_output_size == output_size \n",
        "\n",
        "        self = cls(units=units, output_size=output_size, **kwargs)\n",
        "\n",
        "        self.input_kernel = self.add_weight(shape=(input_shape, self.units),\n",
        "                                      initializer=keras.initializers.constant(input_kernel),\n",
        "                                      trainable = self.__input_kernel_trainable__,\n",
        "                                      name='input_kernel')\n",
        "        \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer=keras.initializers.constant(recurrent_kernel),\n",
        "            trainable = self.__recurrent_kernel_trainable__,\n",
        "            name='recurrent_kernel')\n",
        "        \n",
        "        self.feedback_kernel = self.add_weight(\n",
        "            shape=(self.output_size, self.units),\n",
        "            initializer=keras.initializers.constant(feedback_kernel),\n",
        "            trainable = self.__feedback_kernel_trainable__,\n",
        "            name='feedback_kernel')\n",
        "        \n",
        "        self.output_kernel = self.add_weight(\n",
        "            shape=(self.units, self.output_size),\n",
        "            initializer=keras.initializers.constant(output_kernel),\n",
        "            trainable = self.__output_kernel_trainable__,\n",
        "            name='output_kernel')      \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "        return self\n",
        "\n",
        "class FORCELayer(keras.layers.AbstractRNNCell):\n",
        "    def __init__(self, units, output_size, activation, seed = None, g = 1.5, \n",
        "                 input_kernel_trainable = False, recurrent_kernel_trainable = False, \n",
        "                 output_kernel_trainable = True, feedback_kernel_trainable = False, **kwargs):\n",
        "      \n",
        "        self.units = units \n",
        "        self.__output_size__ = output_size\n",
        "        self.activation = activations.get(activation)\n",
        "\n",
        "        if seed is None:\n",
        "          self.__seed_gen__ = tf.random.Generator.from_non_deterministic_state()\n",
        "        else:\n",
        "          self.__seed_gen__ = tf.random.Generator.from_seed(seed)\n",
        "        \n",
        "        self.__g__ = g\n",
        "\n",
        "        self.__input_kernel_trainable__ = input_kernel_trainable\n",
        "        self.__recurrent_kernel_trainable__ = recurrent_kernel_trainable\n",
        "        self.__feedback_kernel_trainable__ = feedback_kernel_trainable\n",
        "        self.__output_kernel_trainable__ = output_kernel_trainable\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        return [self.units, self.units, self.output_size]\n",
        "\n",
        "    @property \n",
        "    def output_size(self):\n",
        "        return self.__output_size__\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.input_kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1/input_shape[-1]**0.5, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]),\n",
        "          trainable=self.__input_kernel_trainable__,\n",
        "          name='input_kernel')\n",
        " \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "          shape=(self.units, self.units),\n",
        "          initializer= keras.initializers.RandomNormal(mean=0., \n",
        "                                                       stddev= self.__g__/self.units**0.5, \n",
        "                                                       seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                  minval=None, \n",
        "                                                                                  dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__recurrent_kernel_trainable__,\n",
        "          name='recurrent_kernel')\n",
        "        \n",
        "        self.feedback_kernel = self.add_weight(\n",
        "          shape=(self.output_size, self.units), \n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__feedback_kernel_trainable__,\n",
        "          name='feedback_kernel')\n",
        "        \n",
        "        self.output_kernel = self.add_weight(\n",
        "          shape=(self.units, self.output_size),\n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1/self.units**0.5, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__output_kernel_trainable__,\n",
        "          name='output_kernel')      \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    @classmethod\n",
        "    def from_weights(cls, weights, **kwargs):\n",
        "        # Initialize the network from a list of weights (e.g., user-generated)\n",
        "        input_kernel, recurrent_kernel, feedback_kernel, output_kernel = weights \n",
        "        input_shape, input_units = input_kernel.shape \n",
        "        recurrent_units1, recurrent_units2 = recurrent_kernel.shape \n",
        "        feedback_output_size, feedback_units = feedback_kernel.shape \n",
        "        output_units, output_size = output_kernel.shape \n",
        "\n",
        "\n",
        "        units = input_units \n",
        "        assert np.all(np.array([input_units, recurrent_units1, recurrent_units2, \n",
        "                            feedback_units, output_units]) == units)\n",
        "\n",
        "        assert feedback_output_size == output_size \n",
        "\n",
        "        self = cls(units=units, output_size=output_size, **kwargs)\n",
        "\n",
        "        self.input_kernel = self.add_weight(shape=(input_shape, self.units),\n",
        "                                      initializer=keras.initializers.constant(input_kernel),\n",
        "                                      trainable = self.__input_kernel_trainable__,\n",
        "                                      name='input_kernel')\n",
        "        \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer=keras.initializers.constant(recurrent_kernel),\n",
        "            trainable = self.__recurrent_kernel_trainable__,\n",
        "            name='recurrent_kernel')\n",
        "        \n",
        "        self.feedback_kernel = self.add_weight(\n",
        "            shape=(self.output_size, self.units),\n",
        "            initializer=keras.initializers.constant(feedback_kernel),\n",
        "            trainable = self.__feedback_kernel_trainable__,\n",
        "            name='feedback_kernel')\n",
        "        \n",
        "        self.output_kernel = self.add_weight(\n",
        "            shape=(self.units, self.output_size),\n",
        "            initializer=keras.initializers.constant(output_kernel),\n",
        "            trainable = self.__output_kernel_trainable__,\n",
        "            name='output_kernel')      \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "        return self\n",
        "\n",
        "class FORCEModel(keras.Model):\n",
        "    def __init__(self, force_layer, alpha_P=1.,return_sequences=True):\n",
        "        super().__init__()\n",
        "        self.alpha_P = alpha_P\n",
        "        self.force_layer = keras.layers.RNN(force_layer, \n",
        "                                            stateful=True, \n",
        "                                            return_state=True, \n",
        "                                            return_sequences=return_sequences)\n",
        "\n",
        "        self.units = force_layer.units \n",
        "\n",
        "        self.__force_layer__ = force_layer\n",
        " \n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.P_output = self.add_weight(name='P_output', shape=(self.units, self.units), \n",
        "                                 initializer=keras.initializers.Identity(\n",
        "                                              gain=self.alpha_P), trainable=True)\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "        if self.__force_layer__.recurrent_kernel.trainable:\n",
        "\n",
        "            identity_3d = np.zeros((self.units, self.units, self.units))\n",
        "            idx = np.arange(n)\n",
        "\n",
        "#################### \n",
        "\n",
        "            identity_3d[:, idx, idx] = self.alpha_P \n",
        "            I,J = np.nonzero(tf.transpose(self.__force_layer__.recurrent_kernel).numpy()==0)\n",
        "            identity_3d[I,:,J]=0\n",
        "            identity_3d[I,J,:]=0\n",
        "\n",
        "#################### \n",
        "# # new \n",
        "#          #  print('new')\n",
        "#             identity_3d[idx, idx, :] = self.alpha_P \n",
        "#             J,I = np.nonzero(self.__force_layer__.recurrent_kernel.numpy()==0)\n",
        "#             identity_3d[J,:,I]=0\n",
        "#             identity_3d[:,J,I]=0\n",
        "\n",
        "#################### \n",
        "\n",
        "            self.P_GG = self.add_weight(name='P_GG', shape=(self.units, self.units, self.units), \n",
        "                                    initializer=keras.initializers.constant(identity_3d), \n",
        "                                    trainable=True)\n",
        "\n",
        "        self.__output_kernel_idx__ = None\n",
        "        self.__recurrent_kernel_idx__ = None\n",
        "        for idx in range(len(self.trainable_variables)):\n",
        "          trainable_name = self.trainable_variables[idx].name\n",
        "              \n",
        "          if 'output_kernel' in trainable_name:\n",
        "            self.__output_kernel_idx__ = idx\n",
        "          elif 'P_output' in trainable_name:\n",
        "            self.__P_output_idx__ = idx\n",
        "          elif 'P_GG' in trainable_name:\n",
        "            self.__P_GG_idx__ = idx\n",
        "          elif 'recurrent_kernel' in trainable_name:\n",
        "            self.__recurrent_kernel_idx__ = idx\n",
        "\n",
        "\n",
        "    def call(self, x, training=False,   **kwargs):\n",
        "\n",
        "        if training:\n",
        "            return self.force_layer(x, **kwargs) \n",
        "        else:\n",
        "            initialization = all(v is None for v in self.force_layer.states)\n",
        "            \n",
        "            if not initialization:\n",
        "              original_state = [i.numpy() for i in self.force_layer.states]\n",
        "            output = self.force_layer(x, **kwargs)[0] \n",
        "\n",
        "            if not initialization:\n",
        "              self.force_layer.reset_states(states = original_state)\n",
        "            return output\n",
        "\n",
        "    def train_step(self, data):\n",
        "\n",
        "        x, y = data\n",
        "\n",
        "        if self.run_eagerly:\n",
        "          self.hidden_activation = []\n",
        "                \n",
        "        # self.__output_kernel_idx__ = None\n",
        "        # self.__recurrent_kernel_idx__ = None\n",
        "\n",
        "        for i in range(x.shape[1]):\n",
        "          z, _, h, _ = self(x[:,i:i+1,:], training=True)\n",
        "\n",
        "          if self.force_layer.return_sequences:\n",
        "            z = z[:,0,:]\n",
        "         \n",
        "          trainable_vars = self.trainable_variables\n",
        "\n",
        "          # for idx in range(len(trainable_vars)):\n",
        "          #   trainable_name = trainable_vars[idx].name\n",
        "              \n",
        "          #   if 'output_kernel' in trainable_name:\n",
        "          #     self.__output_kernel_idx__ = idx\n",
        "          #   elif 'P_output' in trainable_name:\n",
        "          #     self.__P_output_idx__ = idx\n",
        "          #   elif 'P_GG' in trainable_name:\n",
        "          #     self.__P_GG_idx__ = idx\n",
        "          #   elif 'recurrent_kernel' in trainable_name:\n",
        "          #     self.__recurrent_kernel_idx__ = idx\n",
        "\n",
        "          if self.__output_kernel_idx__ is not None:\n",
        "            assert 'output_kernel' in trainable_vars[self.__output_kernel_idx__].name\n",
        "            assert 'P_output' in trainable_vars[self.__P_output_idx__].name\n",
        "\n",
        "            # Compute pseudogradients\n",
        "            dP = self.__pseudogradient_P(h)\n",
        "            # Update weights\n",
        "            self.optimizer.apply_gradients(zip([dP], [trainable_vars[self.__P_output_idx__]]))\n",
        "\n",
        "            dwO = self.__pseudogradient_wO(h, z, y[:,i,:])\n",
        "            self.optimizer.apply_gradients(zip([dwO], [trainable_vars[self.__output_kernel_idx__]]))\n",
        "          \n",
        "          if self.__recurrent_kernel_idx__ is not None:\n",
        "\n",
        "            assert 'recurrent_kernel' in trainable_vars[self.__recurrent_kernel_idx__].name\n",
        "            assert 'P_GG' in trainable_vars[self.__P_GG_idx__].name\n",
        "\n",
        "            # Compute pseudogradients\n",
        "            dP_GG = self.__pseudogradient_P_Gx(self.P_GG, h)\n",
        "            # Update weights\n",
        "            self.optimizer.apply_gradients(zip([dP_GG], [trainable_vars[self.__P_GG_idx__]]))\n",
        "            dwR = self.__pseudogradient_wR(h, z, y[:,i,:])\n",
        "            self.optimizer.apply_gradients(zip([dwR], [trainable_vars[self.__recurrent_kernel_idx__]]))\n",
        "          \n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "          self.compiled_metrics.update_state(y[:,i,:], z)\n",
        "        # Return a dict mapping metric names to current value\n",
        "\n",
        "          if self.run_eagerly:\n",
        "            self.hidden_activation.append(h.numpy()[0])\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def __pseudogradient_P(self, h):\n",
        "        # Implements the training step i.e. the rls() function\n",
        "        # This not a real gradient (does not use gradient.tape())\n",
        "        # Computes the actual update\n",
        "        # Example array shapes\n",
        "        # h : 1 x 500\n",
        "        # P : 500 x 500 \n",
        "        # k : 500 x 1 \n",
        "        # hPht : 1 x 1\n",
        "        # dP : 500 x 500 \n",
        "\n",
        "\n",
        "        k = backend.dot(self.P_output, tf.transpose(h))\n",
        "        hPht = backend.dot(h, k)\n",
        "        c = 1./(1.+hPht)\n",
        "      #  assert c.shape == (1,1)\n",
        "        hP = backend.dot(h, self.P_output)\n",
        "        dP = backend.dot(c*k, hP)\n",
        "        \n",
        "        return  dP \n",
        "\n",
        "    def __pseudogradient_wO(self, h, z, y):\n",
        "        # z : 1 x 20 \n",
        "        # y : 1 x 20\n",
        "        # e : 1 x 20\n",
        "        # dwO : 500 x 20  \n",
        "\n",
        "        e = z-y\n",
        "        Ph = backend.dot(self.P_output, tf.transpose(h))\n",
        "        dwO = backend.dot(Ph, e)\n",
        "\n",
        "        return  dwO\n",
        "\n",
        "#################### \n",
        "\n",
        "    def __pseudogradient_wR(self, h, z, y):\n",
        "        e = z - y \n",
        "   #     assert e.shape == (1,1)\n",
        "        Ph = backend.dot(self.P_GG, tf.transpose(h))[:,:,0]\n",
        "\n",
        "        dwR = Ph*e ### only valid for 1-d output\n",
        "\n",
        "        return tf.transpose(dwR) \n",
        "\n",
        "    def __pseudogradient_P_Gx(self, P_Gx, h):\n",
        "        Ph = backend.dot(P_Gx, tf.transpose(h))[:,:,0]\n",
        "        hPh = tf.expand_dims(backend.dot(Ph, tf.transpose(h)),axis = 2)\n",
        "        htP = backend.dot(h, P_Gx)[0]\n",
        "        dP_Gx = tf.expand_dims(Ph, axis = 2) * tf.expand_dims(htP, axis = 1)/(1+hPh)\n",
        "        return dP_Gx\n",
        "\n",
        "#################### \n",
        "#new \n",
        "\n",
        "    # def __pseudogradient_wR(self, h, z, y):\n",
        "    #     e = z - y \n",
        "    #     assert e.shape == (1,1)\n",
        "    #     Pht = backend.dot(h, self.P_GG)[0] \n",
        "    #     dwR = e*Pht ### only valid for 1-d output\n",
        "\n",
        "    #     return dwR \n",
        "\n",
        "\n",
        "    # def __pseudogradient_P_Gx(self, P_Gx, h):\n",
        "    #    Pht = backend.dot(h, P_Gx)      # get 1 by j by i\n",
        "    #    hPht = backend.dot(h, Pht)      # get 1 by 1 by i\n",
        "    #    hP = tf.tensordot(h, P_Gx, axes = [[1],[0]]) # get 1 by k by i\n",
        "    #    #dP_Gx = tf.reshape(Pht, (self.units, 1, self.units)) * hP / (1 + hPht)\n",
        "    #    dP_Gx = tf.expand_dims(Pht[0], axis = 1) * hP / (1 + hPht)\n",
        "\n",
        "    #    return dP_Gx\n",
        "\n",
        "#################### \n",
        "\n",
        "    def compile(self, metrics, **kwargs):\n",
        "        super().compile(optimizer=keras.optimizers.SGD(learning_rate=1), loss = 'mae', metrics=metrics,   **kwargs)\n",
        "\n",
        "\n",
        "    def fit(self, x, y=None, epochs = 1, verbose = 'auto', **kwargs):\n",
        "\n",
        "        if len(x.shape) < 2 or len(x.shape) > 3:\n",
        "            raise ValueError('Shape of x is invalid')\n",
        "\n",
        "        if len(y.shape) < 2 or len(y.shape) > 3:\n",
        "            raise ValueError('Shape of y is invalid')\n",
        "        \n",
        "        if len(x.shape) == 2:\n",
        "            x = tf.expand_dims(x, axis = 0)\n",
        "        \n",
        "        if len(y.shape) == 2:\n",
        "            y = tf.expand_dims(y, axis = 0)\n",
        "        \n",
        "        if x.shape[0] != 1:\n",
        "            raise ValueError(\"Dim 0 of x must be 1\")\n",
        "\n",
        "        if y.shape[0] != 1:\n",
        "            raise ValueError(\"Dim 0 of y must be 1\")\n",
        "        \n",
        "        if x.shape[1] != y.shape[1]: \n",
        "            raise ValueError('Timestep dimension of inputs must match')     \n",
        "\n",
        "        return super().fit(x = x, y = y, epochs = epochs, batch_size = 1, verbose = verbose, **kwargs)\n",
        "\n",
        "    def predict(self, x, **kwargs):\n",
        "        if len(x.shape) == 3 and x.shape[0] != 1:\n",
        "            raise ValueError('Dim 0 must be 1')\n",
        "        \n",
        "        if len(x.shape) < 2 or len(x.shape) > 3:\n",
        "            raise ValueError('')\n",
        "\n",
        "        if len(x.shape) == 2:\n",
        "            x = tf.expand_dims(x, axis = 0)\n",
        "\n",
        "        return self(x, training = False)[0]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOgXOO5M-nzz"
      },
      "source": [
        "class EchoStateNetwork(FORCELayer):\n",
        "    def __init__(self, dtdivtau, hscale = 0.25, initial_a = None, **kwargs):\n",
        "        self.dtdivtau = dtdivtau \n",
        "        self.hscale = hscale\n",
        "        self.__initial_a__ = initial_a\n",
        "        super().__init__(**kwargs)        \n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        \"\"\"Implements the forward step (i.e., the esn() function)\n",
        "        \"\"\"\n",
        "        prev_a, prev_h, prev_output = states      \n",
        "        input_term = backend.dot(inputs, self.input_kernel)\n",
        "        recurrent_term = backend.dot(prev_h, self.recurrent_kernel)\n",
        "        feedback_term = backend.dot(prev_output, self.feedback_kernel)\n",
        "\n",
        "        dadt = -prev_a + input_term + recurrent_term + feedback_term \n",
        "        a = prev_a + self.dtdivtau * dadt\n",
        "        h = self.activation(a)\n",
        "        output = backend.dot(h, self.output_kernel)\n",
        "\n",
        "        return output, [a, h, output]\n",
        "\n",
        "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
        "\n",
        "        if self.__initial_a__ is not None:\n",
        "          init_a = self.__initial_a__\n",
        "        else:\n",
        "          initializer = keras.initializers.RandomNormal(mean=0., \n",
        "                                                        stddev= self.hscale , \n",
        "                                                        seed = self.__seed_gen__.uniform([1], \n",
        "                                                                                        minval=None, \n",
        "                                                                                        dtype=tf.dtypes.int64)[0])\n",
        "          init_a = initializer((batch_size, self.units))  \n",
        "\n",
        "        init_h =  self.activation(init_a)\n",
        "        init_out = backend.dot(init_h,self.output_kernel) \n",
        "\n",
        "        return (init_a, init_h, init_out)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIrvGqvUSfV"
      },
      "source": [
        "class NoFeedbackESN(EchoStateNetwork):\n",
        "\n",
        "    def __init__(self, recurrent_kernel_trainable  = True, **kwargs):\n",
        "        super().__init__(recurrent_kernel_trainable = recurrent_kernel_trainable, **kwargs)\n",
        "    \n",
        "    \n",
        "    def call(self, inputs, states):\n",
        "        \"\"\"Implements the forward step (i.e., the esn() function)\n",
        "        \"\"\"\n",
        "        prev_a, prev_h, prev_output = states      \n",
        "        input_term = backend.dot(inputs, self.input_kernel)\n",
        "        recurrent_term = backend.dot(prev_h, self.recurrent_kernel)\n",
        "\n",
        "        dadt = -prev_a + input_term + recurrent_term \n",
        "        a = prev_a + self.dtdivtau * dadt\n",
        "        h = self.activation(a)\n",
        "        output = backend.dot(h, self.output_kernel)\n",
        "\n",
        "        return output, [a, h, output]\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.input_kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1/input_shape[-1]**0.5, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]),\n",
        "          trainable=self.__input_kernel_trainable__,\n",
        "          name='input_kernel')\n",
        " \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "          shape=(self.units, self.units),\n",
        "          initializer= keras.initializers.RandomNormal(mean=0., \n",
        "                                                       stddev= self.__g__/self.units**0.5, \n",
        "                                                       seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                  minval=None, \n",
        "                                                                                  dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__recurrent_kernel_trainable__,\n",
        "          name='recurrent_kernel')\n",
        "        \n",
        "        self.output_kernel = self.add_weight(\n",
        "          shape=(self.units, self.output_size),\n",
        "          initializer=keras.initializers.RandomNormal(mean=0., \n",
        "                                                      stddev= 1/self.units**0.5, \n",
        "                                                      seed=self.__seed_gen__.uniform([1], \n",
        "                                                                                 minval=None, \n",
        "                                                                                 dtype=tf.dtypes.int64)[0]), \n",
        "          trainable=self.__output_kernel_trainable__,\n",
        "          name='output_kernel')      \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    @classmethod\n",
        "    def from_weights(cls, weights, **kwargs):\n",
        "        # Initialize the network from a list of weights (e.g., user-generated)\n",
        "        input_kernel, recurrent_kernel, output_kernel = weights \n",
        "        input_shape, input_units = input_kernel.shape \n",
        "        recurrent_units1, recurrent_units2 = recurrent_kernel.shape \n",
        "        output_units, output_size = output_kernel.shape \n",
        "\n",
        "\n",
        "        units = input_units \n",
        "        assert np.all(np.array([input_units, recurrent_units1, recurrent_units2, \n",
        "                            output_units]) == units)\n",
        "\n",
        "        self = cls(units=units, output_size=output_size, **kwargs)\n",
        "\n",
        "        self.input_kernel = self.add_weight(shape=(input_shape, self.units),\n",
        "                                      initializer=keras.initializers.constant(input_kernel),\n",
        "                                      trainable = self.__input_kernel_trainable__,\n",
        "                                      name='input_kernel')\n",
        "        \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer=keras.initializers.constant(recurrent_kernel),\n",
        "            trainable = self.__recurrent_kernel_trainable__,\n",
        "            name='recurrent_kernel')\n",
        " \n",
        "        \n",
        "        self.output_kernel = self.add_weight(\n",
        "            shape=(self.units, self.output_size),\n",
        "            initializer=keras.initializers.constant(output_kernel),\n",
        "            trainable = self.__output_kernel_trainable__,\n",
        "            name='output_kernel')      \n",
        "\n",
        "        self.built = True\n",
        "\n",
        "        return self"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8HRyNVQzgm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdX7x2wFYfoS"
      },
      "source": [
        "# Original\n",
        "# class EarlyStoppingByLossVal(keras.callbacks.Callback):\n",
        "#     def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n",
        "#         super().__init__()\n",
        "#         self.monitor = monitor\n",
        "#         self.value = value\n",
        "#         self.verbose = verbose\n",
        "\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         current = logs.get(self.monitor)\n",
        "#         if current is None:\n",
        "#             warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "\n",
        "#         if current < self.value:\n",
        "#             if self.verbose > 0:\n",
        "#                 print(\"Epoch %05d: early stopping THR\" % epoch)\n",
        "#             self.model.stop_training = True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC_pE1iGaUZ7"
      },
      "source": [
        "# class EarlyStoppingByVal(keras.callbacks.Callback):\n",
        "#     def __init__(self, monitor='mae', thresh = 0.00001, value=0.00001, total_epoch = 7, verbose=0):\n",
        "#         super().__init__()\n",
        "#         self.monitor = monitor\n",
        "#         self.value = value\n",
        "#         self.verbose = verbose\n",
        "#         self.tracking = []\n",
        "#         self.total = 0\n",
        "#         self.total_epoch = total_epoch\n",
        "#         self.thresh = thresh\n",
        "\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         current = logs.get(self.monitor)\n",
        "\n",
        "#         if current is None:\n",
        "#             warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "        \n",
        "#         temp = (current < self.value)\n",
        "#         self.tracking.append(temp)\n",
        "#         self.total += temp\n",
        "\n",
        "#         if len(self.tracking) > self.total_epoch:\n",
        "#           self.total -= self.tracking.pop(0)\n",
        "        \n",
        "#         if self.total == self.total_epoch and current < self.thresh:\n",
        "#             if self.verbose > 0:\n",
        "#                 print(\"Epoch %05d: early stopping THR\" % epoch)\n",
        "#             self.model.stop_training = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKI_71S8narL"
      },
      "source": [
        "myesn = NoFeedbackESN( dtdivtau= dtdivtau, units = n, \n",
        "                          output_size = m, activation = 'tanh')\n",
        "\n",
        "# myesn = EchoStateNetwork.from_weights(dtdivtau=dtdivtau, \n",
        "#                                       initial_a = a0,\n",
        "#                                       weights = (wI, wR, wF, wO), \n",
        "#                                       activation = 'tanh' )\n",
        "\n",
        "model = FORCEModel(myesn, return_sequences=True)  \n",
        "model.compile(metrics=[\"mae\"], run_eagerly = False)\n",
        " \n",
        "# early_stopping = EarlyStoppingByVal(monitor='mae', thresh = 0.01, value=0.02, total_epoch = 500, verbose=1)\n",
        "# model_chkpt = keras.callbacks.ModelCheckpoint(\n",
        "#     'saved_model.h5',\n",
        "#     monitor='mae',\n",
        "#     mode='min',\n",
        "#     verbose = 1,\n",
        "#     save_weights_only = True, \n",
        "#     save_best_only=True)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD3tnJ1bnaud",
        "outputId": "a2f4a0ee-1166-4eae-f547-78762c337173"
      },
      "source": [
        "history = model.fit(x=input1 , y= f_t_1, epochs = 250) #, callbacks=[early_stopping]) #callbacks=[early_stopping, model_chkpt])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1/1 [==============================] - 359s 359s/step - mae: 0.2370\n",
            "Epoch 2/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.2248\n",
            "Epoch 3/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.2306\n",
            "Epoch 4/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1908\n",
            "Epoch 5/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1913\n",
            "Epoch 6/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1655\n",
            "Epoch 7/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1566\n",
            "Epoch 8/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1502\n",
            "Epoch 9/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1469\n",
            "Epoch 10/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1440\n",
            "Epoch 11/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1416\n",
            "Epoch 12/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1402\n",
            "Epoch 13/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1398\n",
            "Epoch 14/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1397\n",
            "Epoch 15/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1391\n",
            "Epoch 16/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1384\n",
            "Epoch 17/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1374\n",
            "Epoch 18/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1362\n",
            "Epoch 19/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1349\n",
            "Epoch 20/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1335\n",
            "Epoch 21/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1322\n",
            "Epoch 22/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1308\n",
            "Epoch 23/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1296\n",
            "Epoch 24/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1283\n",
            "Epoch 25/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1272\n",
            "Epoch 26/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1261\n",
            "Epoch 27/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1252\n",
            "Epoch 28/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1243\n",
            "Epoch 29/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1235\n",
            "Epoch 30/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1227\n",
            "Epoch 31/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1221\n",
            "Epoch 32/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1215\n",
            "Epoch 33/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1210\n",
            "Epoch 34/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1204\n",
            "Epoch 35/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1200\n",
            "Epoch 36/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1195\n",
            "Epoch 37/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1190\n",
            "Epoch 38/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1185\n",
            "Epoch 39/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1180\n",
            "Epoch 40/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1174\n",
            "Epoch 41/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1169\n",
            "Epoch 42/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1166\n",
            "Epoch 43/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1164\n",
            "Epoch 44/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1158\n",
            "Epoch 45/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1151\n",
            "Epoch 46/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1145\n",
            "Epoch 47/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1140\n",
            "Epoch 48/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1136\n",
            "Epoch 49/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1136\n",
            "Epoch 50/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1139\n",
            "Epoch 51/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1132\n",
            "Epoch 52/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1119\n",
            "Epoch 53/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1117\n",
            "Epoch 54/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1122\n",
            "Epoch 55/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1119\n",
            "Epoch 56/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1102\n",
            "Epoch 57/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1140\n",
            "Epoch 58/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1398\n",
            "Epoch 59/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.2408\n",
            "Epoch 60/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1995\n",
            "Epoch 61/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1968\n",
            "Epoch 62/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1219\n",
            "Epoch 63/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1154\n",
            "Epoch 64/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1153\n",
            "Epoch 65/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1149\n",
            "Epoch 66/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1144\n",
            "Epoch 67/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1143\n",
            "Epoch 68/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1146\n",
            "Epoch 69/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1149\n",
            "Epoch 70/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1151\n",
            "Epoch 71/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1154\n",
            "Epoch 72/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1154\n",
            "Epoch 73/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1150\n",
            "Epoch 74/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1145\n",
            "Epoch 75/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1142\n",
            "Epoch 76/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1134\n",
            "Epoch 77/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1129\n",
            "Epoch 78/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1123\n",
            "Epoch 79/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1117\n",
            "Epoch 80/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1114\n",
            "Epoch 81/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1109\n",
            "Epoch 82/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1105\n",
            "Epoch 83/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1099\n",
            "Epoch 84/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1095\n",
            "Epoch 85/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1090\n",
            "Epoch 86/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1088\n",
            "Epoch 87/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1083\n",
            "Epoch 88/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1077\n",
            "Epoch 89/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1073\n",
            "Epoch 90/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1068\n",
            "Epoch 91/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1064\n",
            "Epoch 92/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1061\n",
            "Epoch 93/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1057\n",
            "Epoch 94/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1052\n",
            "Epoch 95/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1048\n",
            "Epoch 96/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1045\n",
            "Epoch 97/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1041\n",
            "Epoch 98/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1038\n",
            "Epoch 99/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1035\n",
            "Epoch 100/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1031\n",
            "Epoch 101/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1027\n",
            "Epoch 102/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1025\n",
            "Epoch 103/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1022\n",
            "Epoch 104/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1019\n",
            "Epoch 105/250\n",
            "1/1 [==============================] - 36s 36s/step - mae: 0.1017\n",
            "Epoch 106/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1015\n",
            "Epoch 107/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1013\n",
            "Epoch 108/250\n",
            "1/1 [==============================] - 37s 37s/step - mae: 0.1011\n",
            "Epoch 109/250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VHT8ZzTJ2Gr"
      },
      "source": [
        "#model.load_weights('/content/saved_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdZ9D2eynaxl"
      },
      "source": [
        "z_t_call = model.predict(input1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwNzwhaQKeUX"
      },
      "source": [
        "np.mean(np.abs(z_t_call - f_t_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehJquVbikeLX"
      },
      "source": [
        "z_t_call.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZFsALNAna3Y"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, sharey = True, figsize=(24,6))\n",
        "\n",
        "\n",
        "ax1.plot(time , f_t_1  + 2*np.arange(0, f_t_1.shape[1]), 'g')\n",
        "ax1.plot(time , z_t_call + 2*np.arange(0, z_t_call.shape[1]), 'r');\n",
        " \n",
        "ax1.set_xlim((0, T))\n",
        "plt.title('Target - f (green), Output - z (red)')\n",
        "ax1.set_xlabel('Time')\n",
        "ax1.set_ylabel('Dimension')\n",
        "\n",
        "ax2.plot(time, tf.math.abs(f_t_1-z_t_call) + 2*np.arange(0, z_t_call.shape[1]), 'r');\n",
        "ax2.set_xlim((0, T))\n",
        "plt.title('MAE')\n",
        "ax2.set_xlabel('Time')\n",
        "ax2.set_ylabel('Dimension')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKYtVnJmxmuG"
      },
      "source": [
        "plt.figure(figsize=(12,8), dpi=80)\n",
        "plt.plot(history.history['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKmLrPlQvmLn"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOBjWwwoktn"
      },
      "source": [
        "x_t_2 = np.zeros((ntime,u)) # Just a stand-in in folks want a real input later\n",
        "indices = np.random.choice(x_t_2.shape[0] *x_t_2.shape[1], replace=False,\n",
        "                           size=int(x_t_2.shape[0] *x_t_2.shape[1] * 0.025))\n",
        "x_t_2[np.unravel_index(indices, x_t_2.shape)] = 0.375\n",
        "\n",
        "for i in range(x_t_2.shape[0]):\n",
        "  if np.sum(x_t_2[i-10:i,:]) > 0:\n",
        "    x_t_2[i,:] = 0\n",
        "\n",
        "input2 = tf.cast(tf.expand_dims(x_t_2,0),np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcDPUnDjouID"
      },
      "source": [
        "z_t_call_2 = model.predict(input2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIdt71i5qDb_"
      },
      "source": [
        "f_t_2 = np.zeros((x_t_2.shape[0],1))-1\n",
        "\n",
        "f_t_2 =  func(f_t_2, x_t_2) \n",
        "f_t_2[:,0] = butter_lowpass_filter(f_t_2[:,0], cutoff, fs, order)\n",
        "f_t_2 = tf.cast(f_t_2,np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JBt7xavpU98"
      },
      "source": [
        "f, (ax0, ax1, ax2) = plt.subplots(nrows = 3, sharex = True,figsize = (18,6))\n",
        "\n",
        "ax0.plot(z_t_call_2[:,0])\n",
        "ax0.plot(f_t_2[:,0])\n",
        "ax1.plot(x_t_2[:,0])\n",
        "ax2.plot(x_t_2[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}